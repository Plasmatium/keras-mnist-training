{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout, BatchNormalization, MaxPool2D, Flatten, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "files = ['test-img.data', 'test-label.data', 'train-img.data', 'train-label.data']\n",
    "for file in files:\n",
    "    with open('../mnist-dataset/'+file, 'rb') as f:\n",
    "        data = f.read()\n",
    "        dataset[file[:-5]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理数据\n",
    "\n",
    "def convert_to_one_hot(y, C):\n",
    "    return np.eye(C, dtype=np.uint8)[y.reshape(-1)]\n",
    "\n",
    "testImg = np.fromiter(dataset['test-img'][16:], np.float)\n",
    "X_test = testImg.reshape([-1, 28, 28, 1])/255.0 - 0.5\n",
    "\n",
    "trainImg = np.fromiter(dataset['train-img'][16:], np.float)\n",
    "trainImg = trainImg.reshape([-1, 28, 28, 1])/255.0 - 0.5\n",
    "\n",
    "testLabel = np.fromiter(dataset['test-label'][8:], np.uint8)\n",
    "Y_test = convert_to_one_hot(testLabel, 10)\n",
    "\n",
    "trainLabel = np.fromiter(dataset['train-label'][8:], np.uint8)\n",
    "trainLabel = convert_to_one_hot(trainLabel, 10)\n",
    "\n",
    "validRatio = 0.1\n",
    "validLen = int(validRatio * len(trainImg))\n",
    "X_valid, X_train = trainImg[:validLen], trainImg[validLen:]\n",
    "Y_valid, Y_train = trainLabel[:validLen], trainLabel[validLen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_152 (Conv2D)          (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 12, 12, 16)        1168      \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_123 (MaxPoolin (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_132 (Bat (None, 6, 6, 16)          64        \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 4, 4, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_155 (Conv2D)          (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_124 (MaxPoolin (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_133 (Bat (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_52 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_134 (Bat (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 25,978\n",
      "Trainable params: 25,786\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建卷积网络\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(3,3), batch_input_shape=(None, 28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3,3), strides=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.00001))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.15, height_shift_range=0.15, zoom_range=0.15)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 10s 185us/step - loss: 0.0137 - val_loss: 0.0486\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 10s 185us/step - loss: 0.0134 - val_loss: 0.0484\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 10s 184us/step - loss: 0.0135 - val_loss: 0.0484\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 10s 185us/step - loss: 0.0132 - val_loss: 0.0484\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 10s 185us/step - loss: 0.0131 - val_loss: 0.0483\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 10s 185us/step - loss: 0.0129 - val_loss: 0.0481\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 10s 185us/step - loss: 0.0127 - val_loss: 0.0483\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 10s 184us/step - loss: 0.0123 - val_loss: 0.0481\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 10s 184us/step - loss: 0.0124 - val_loss: 0.0482\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 10s 185us/step - loss: 0.0122 - val_loss: 0.0482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160369c88>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          batch_size=256, epochs=10, verbose=1,\n",
    "          validation_data=(X_valid, Y_valid), shuffle=True)\n",
    "# model.fit_generator(datagen.flow(X_train, Y_train, batch_size=256),\n",
    "#                     steps_per_epoch=len(X_train)/10, epochs=5, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 138us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9873"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(X_test, verbose=1)\n",
    "accu = np.argmax(p, axis=1) == np.argmax(Y_test, axis=1)\n",
    "sum(accu) / len(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x128a96eb8>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[18].reshape(28, 28), cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(p[18]))\n",
    "print(np.argmax(Y_test[18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('conv-mnist.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
